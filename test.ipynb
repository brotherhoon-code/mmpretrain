{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dw-p'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = [\"(dw-p)x3\", \"(dw-p)x3\", \"(dw-p)x3\", \"(dw-p)\"]\n",
    "input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brotherhoon88/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 96, 58, 58])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,\n",
    "                 normalized_shape,\n",
    "                 eps=1e-6,\n",
    "                 data_format=\"channels_first\"):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape)) # dim\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape)) # dim\n",
    "        self.eps = eps # 분모에 더해지는 작은 값\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError\n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "        \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(dim=1, keepdim=True)\n",
    "            s = (x-u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x-u)/torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None]*x + self.bias[:, None, None]\n",
    "            return x\n",
    "        \n",
    "LayerNorm(96,data_format=\"channels_first\")(torch.Tensor(64, 96, 58, 58)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input = torch.Tensor(64,96,7,7)\n",
    "avgpool = nn.AdaptiveAvgPool2d(output_size=(16,16))\n",
    "avgpool(input).shape\n",
    "\n",
    "16*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6.6728e-35, 0.0000e+00],\n",
      "          [2.6768e+03, 4.5741e-41]]]])\n",
      "tensor([[[[6.6728e-34, 0.0000e+00],\n",
      "          [2.6768e+04, 4.5741e-40]]]])\n",
      "tensor([[[[True, True],\n",
      "          [True, True]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(1,1,2,2)\n",
    "print(x)\n",
    "y = x*10\n",
    "print(y)\n",
    "z = x + y\n",
    "print(z ==  x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brotherhoon88/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 96, 7, 7]) torch.Size([96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072, 52, 52])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "conv0 = nn.Conv2d(\n",
    "    in_channels=96,\n",
    "    out_channels=96,\n",
    "    kernel_size=7,\n",
    "    stride=1,\n",
    "    padding=int(7 // 2),\n",
    "    groups=1,\n",
    "    bias=True,\n",
    ")\n",
    "print(conv0.weight.shape, conv0.bias.shape) # torch.Size([96, 1, 7, 7]) torch.Size([96]), torch.Size([96, 96, 7, 7]) torch.Size([96])\n",
    "\n",
    "input = torch.randn(32, 96, 52, 52)\n",
    "input = input.reshape(1, -1, 52, 52)\n",
    "attn_weight = torch.Tensor(32 * 96, 1, 7, 7)\n",
    "attn_bias = torch.Tensor(32*96)\n",
    "\n",
    "out = F.conv2d(\n",
    "    input, weight=attn_weight, bias=attn_bias, stride=1, padding=int(7 // 2), groups=32 * 96\n",
    ")\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 예시 입력 데이터\n",
    "batch_size = 10\n",
    "input_channels = 3\n",
    "input_height = 32\n",
    "input_width = 32\n",
    "\n",
    "# 커널 크기와 스트라이드 설정\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1\n",
    "\n",
    "# Depthwise Convolution 수행\n",
    "input_data = torch.randn(batch_size, input_channels, input_height, input_width)\n",
    "depthwise_weight = torch.randn(input_channels, 1, kernel_size, kernel_size)  # depthwise convolution의 가중치\n",
    "depthwise_bias = torch.randn(input_channels)  # depthwise convolution의 bias\n",
    "\n",
    "# depthwise convolution 수행\n",
    "output = F.conv2d(input_data, depthwise_weight, bias=depthwise_bias, stride=stride, padding=padding, groups=input_channels)\n",
    "\n",
    "# 출력 크기 확인\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "\n",
    "\n",
    "def profile_model(model:nn.Module):\n",
    "    M=model # your model\n",
    "    summary(M, (3, 224, 224), batch_size=256, device=\"cpu\") #모델 서머리\n",
    "    flops = FlopCountAnalysis(M, torch.Tensor(1,3,224,224))\n",
    "    print(flop_count_table(flops)) #프로파일링\n",
    "    formatted_number = \"{:.2f}G\".format(flops.total() / 1e9)\n",
    "    print(formatted_number) # 플롭스"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
